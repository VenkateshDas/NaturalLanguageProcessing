{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.',\n",
       " 'Welcome to GeeksforGeeks.',\n",
       " 'You are studying NLP article']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize \n",
    "  \n",
    "text = \"Hello everyone. Welcome to GeeksforGeeks. You are studying NLP article\"\n",
    "sent_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.',\n",
       " 'Welcome to GeeksforGeeks.',\n",
       " 'You are studying NLP article']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data \n",
    "  \n",
    "# Loading PunktSentenceTokenizer using English pickle file \n",
    "tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle') \n",
    "  \n",
    "tokenizer.tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola amigo.', 'Estoy bien.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data \n",
    "  \n",
    "spanish_tokenizer = nltk.data.load('tokenizers/punkt/PY3/spanish.pickle') \n",
    "  \n",
    "text = 'Hola amigo. Estoy bien.'\n",
    "spanish_tokenizer.tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Writers write descriptive paragraphs because their purpose is to describe something.', 'Their point is that something is beautiful or disgusting or strangely intriguing.', 'Writers write persuasive and argument paragraphs because their purpose is to persuade or convince someone.', 'Their point is that their reader should see things a particular way and possibly take action on that new way of seeing things.', 'Writers write paragraphs of comparison because the comparison will make their point clear to their readers.']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"\"\"Writers write descriptive paragraphs because their purpose is to describe something. Their point is that something is beautiful or disgusting or strangely intriguing. Writers write persuasive and argument paragraphs because their purpose is to persuade or convince someone. Their point is that their reader should see things a particular way and possibly take action on that new way of seeing things. Writers write paragraphs of comparison because the comparison will make their point clear to their readers.\"\"\"\n",
    "\n",
    "sent_text = nltk.sent_tokenize(text)\n",
    "# this gives us a list of sentences\n",
    "\n",
    "print(sent_text)\n",
    "print(len(sent_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Writers', 'NNS'), ('write', 'VBP'), ('descriptive', 'JJ'), ('paragraphs', 'NN'), ('because', 'IN'), ('their', 'PRP$'), ('purpose', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('describe', 'VB'), ('something', 'NN'), ('.', '.')]\n",
      "[('Their', 'PRP$'), ('point', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('something', 'NN'), ('is', 'VBZ'), ('beautiful', 'JJ'), ('or', 'CC'), ('disgusting', 'VBG'), ('or', 'CC'), ('strangely', 'RB'), ('intriguing', 'JJ'), ('.', '.')]\n",
      "[('Writers', 'NNS'), ('write', 'VBP'), ('persuasive', 'JJ'), ('and', 'CC'), ('argument', 'JJ'), ('paragraphs', 'NN'), ('because', 'IN'), ('their', 'PRP$'), ('purpose', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('persuade', 'VB'), ('or', 'CC'), ('convince', 'VB'), ('someone', 'NN'), ('.', '.')]\n",
      "[('Their', 'PRP$'), ('point', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('their', 'PRP$'), ('reader', 'NN'), ('should', 'MD'), ('see', 'VB'), ('things', 'NNS'), ('a', 'DT'), ('particular', 'JJ'), ('way', 'NN'), ('and', 'CC'), ('possibly', 'RB'), ('take', 'VB'), ('action', 'NN'), ('on', 'IN'), ('that', 'DT'), ('new', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('seeing', 'VBG'), ('things', 'NNS'), ('.', '.')]\n",
      "[('Writers', 'NNS'), ('write', 'VBP'), ('paragraphs', 'NN'), ('of', 'IN'), ('comparison', 'NN'), ('because', 'IN'), ('the', 'DT'), ('comparison', 'NN'), ('will', 'MD'), ('make', 'VB'), ('their', 'PRP$'), ('point', 'NN'), ('clear', 'VBP'), ('to', 'TO'), ('their', 'PRP$'), ('readers', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# now loop over each sentence and tokenize it separately\n",
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence) # word tokenization \n",
    "    tagged = nltk.pos_tag(tokenized_text) #POS Tagging (Will be covered exclusively in another notebook)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
