{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the basics of tokenization of words and a little introduction to named entity recognition(NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer \n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ok....by the way, so according to the new rule how much per month should be the new blocked account amount be? +86 999 89898 98989\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', '...', '.by', 'the', 'way', ',', 'so', 'according', 'to', 'the', 'new', 'rule', 'how', 'much', 'per', 'month', 'should', 'be', 'the', 'new', 'blocked', 'account', 'amount', 'be', '?', '+86', '999', '89898', '98989']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', '....', 'by', 'the', 'way', ',', 'so', 'according', 'to', 'the', 'new', 'rule', 'how', 'much', 'per', 'month', 'should', 'be', 'the', 'new', 'blocked', 'account', 'amount', 'be', '?']\n"
     ]
    }
   ],
   "source": [
    "Punctuation_tokenizer  = WordPunctTokenizer() \n",
    "tokens1 = Punctuation_tokenizer.tokenize(text)\n",
    "print(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', '....', 'by', 'the', 'way', ',', 'so', 'according', 'to', 'the', 'new', 'rule', 'how', 'much', 'per', 'month', 'should', 'be', 'the', 'new', 'blocked', 'account', 'amount', 'be', '?', '+', '86', '999', '89898', '98989']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "file = nlp(text)\n",
    "tokens = [token.text for token in file]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both are same\n"
     ]
    }
   ],
   "source": [
    "if tokens1 == tokens:\n",
    "    print(\"Both are same\")\n",
    "    \n",
    "else:\n",
    "    print(\"They are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', 'by', 'the', 'way', 'so', 'according', 'to', 'the', 'new', 'rule', 'how', 'much', 'per', 'month', 'should', 'be', 'the', 'new', 'blocked', 'account', 'amount', 'be']\n"
     ]
    }
   ],
   "source": [
    "#Filtering out the punctuation marks\n",
    "\n",
    "only_words = [word for word in tokens1 if word.isalpha()]\n",
    "print(only_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', 'way', 'according', 'new', 'rule', 'much', 'per', 'month', 'new', 'blocked', 'account', 'amount']\n"
     ]
    }
   ],
   "source": [
    "#filtering out the stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "final_word = [word for word in only_words if not word in stop_words]\n",
    "print(final_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ok', '...', '.by', 'the', 'way', ',', 'so', 'according', 'to', 'the', 'new', 'rule', 'how', 'much', 'per', 'month', 'should', 'be', 'the', 'new', 'blocked', 'account', 'amount', 'be', '?', 'replaced']\n"
     ]
    }
   ],
   "source": [
    "#this is a very naive way of replacing texts that can be used for custom tokenization. This can be used as a separate function. \n",
    "\n",
    "import re\n",
    "\n",
    "expression = r\"[+][\\d]{0,2}[\\s][\\d]{0,3}[\\s][\\d]{0,5}[\\s][\\d]{0,5}\"\n",
    "phone = re.compile(expression)\n",
    "text = re.sub(expression,\"replaced\",text)\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"Ok....by the way , so according to the new rule how much per month should be the new blocked account amount be?\"\n",
    "new_file = nlp(new_text)\n",
    "for entity in new_file.ents:\n",
    "    print(\"Its working\")\n",
    "    entitylist = [entity.text]\n",
    "    if len(entitylist) > 0:\n",
    "        print(entity.text, entity.label_)    \n",
    "    else: \n",
    "        print(\"no entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Apple ORG\n",
      "1\n",
      "California GPE\n",
      "1\n",
      "Ferrari PERSON\n"
     ]
    }
   ],
   "source": [
    "new_text = \"I am the CEO of Apple. I live in California.I drive Ferrari.+86 999 89898 98989\"\n",
    "new_file = nlp(new_text)\n",
    "for entity in new_file.ents:\n",
    "    entitylist = [entity.text]\n",
    "    if len(entitylist) > 0:\n",
    "        print(entity.text, entity.label_)    \n",
    "    else: \n",
    "        print(\"no entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entity\n"
     ]
    }
   ],
   "source": [
    "new_text = \"Ok....by the way , so according to the new rule how much per month should be the new blocked account amount be?\"\n",
    "new_file = nlp(new_text)\n",
    "entitieslist = []\n",
    "for entity in new_file.ents:\n",
    "    entitieslist = entity\n",
    "if len(entitieslist) > 0:\n",
    "    print(entitieslist)\n",
    "else:\n",
    "    print(\"no entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNITED', 'STATES', 'of', 'America', ',', 'Plaintiff–', '\\n', 'Appellee', ',', 'v.', 'Matthew', 'R.', 'LANGE', ',', '\\n', 'disorder', '(', 'PTSD', ')', '.', '\\n   ', 'Defendant', '–', 'Appellant']\n",
      "['UNITED', 'STATES', 'of', 'America', ',', 'Plaintiff–', 'Appellee', ',', 'v.', 'Matthew', 'R.', 'LANGE', ',', 'disorder', '(', 'PTSD', ')', '.', 'Defendant–Appellant']\n",
      "['UNITED STATES of America, Plaintiff–\\nAppellee, v. Matthew R. LANGE,\\ndisorder (PTSD).', 'Defendant–Appellant']\n",
      "['UNITED STATES of America, Plaintiff–\\n', 'Appellee, v. Matthew R. LANGE,\\ndisorder (PTSD).\\n   ', 'Defendant–Appellant']\n"
     ]
    }
   ],
   "source": [
    "#text_1 = \" I am Dr.Suresh. I live in St.Pauls Hospital. He is Mr..\"\n",
    "text_1 = \"\"\"UNITED STATES of America, Plaintiff–\n",
    "Appellee, v. Matthew R. LANGE,\n",
    "disorder (PTSD).\n",
    "   Defendant–Appellant\"\"\"\n",
    "file_1 = nlp(text_1)\n",
    "tokens_new =[token.text for token in file_1]\n",
    "print(tokens_new)\n",
    "print(word_tokenize(text_1))\n",
    "print(sent_tokenize(text_1))\n",
    "sents = [sent.text for sent in file_1.sents]\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
