{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"For nearly a decade, they argue, Facebook has made “serial defensive acquisitions” to protect its dominant position in the market for social networks, according to slides they have shown government officials. Scooping up nascent rivals, they assert, can allow Facebook to charge advertisers higher prices and can give users worse experience.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('For', 'IN'),\n",
      " ('nearly', 'RB'),\n",
      " ('a', 'DT'),\n",
      " ('decade', 'NN'),\n",
      " (',', ','),\n",
      " ('they', 'PRP'),\n",
      " ('argue', 'VBP'),\n",
      " (',', ','),\n",
      " ('Facebook', 'NNP'),\n",
      " ('has', 'VBZ'),\n",
      " ('made', 'VBN'),\n",
      " ('“', 'NNP'),\n",
      " ('serial', 'JJ'),\n",
      " ('defensive', 'JJ'),\n",
      " ('acquisitions', 'NNS'),\n",
      " ('”', 'VBP'),\n",
      " ('to', 'TO'),\n",
      " ('protect', 'VB'),\n",
      " ('its', 'PRP$'),\n",
      " ('dominant', 'JJ'),\n",
      " ('position', 'NN'),\n",
      " ('in', 'IN'),\n",
      " ('the', 'DT'),\n",
      " ('market', 'NN'),\n",
      " ('for', 'IN'),\n",
      " ('social', 'JJ'),\n",
      " ('networks', 'NNS'),\n",
      " (',', ','),\n",
      " ('according', 'VBG'),\n",
      " ('to', 'TO'),\n",
      " ('slides', 'NNS'),\n",
      " ('they', 'PRP'),\n",
      " ('have', 'VBP'),\n",
      " ('shown', 'VBN'),\n",
      " ('government', 'NN'),\n",
      " ('officials', 'NNS'),\n",
      " ('.', '.'),\n",
      " ('Scooping', 'VBG'),\n",
      " ('up', 'RP'),\n",
      " ('nascent', 'JJ'),\n",
      " ('rivals', 'NNS'),\n",
      " (',', ','),\n",
      " ('they', 'PRP'),\n",
      " ('assert', 'VBP'),\n",
      " (',', ','),\n",
      " ('can', 'MD'),\n",
      " ('allow', 'VB'),\n",
      " ('Facebook', 'NNP'),\n",
      " ('to', 'TO'),\n",
      " ('charge', 'VB'),\n",
      " ('advertisers', 'NNS'),\n",
      " ('higher', 'JJR'),\n",
      " ('prices', 'NNS'),\n",
      " ('and', 'CC'),\n",
      " ('can', 'MD'),\n",
      " ('give', 'VB'),\n",
      " ('users', 'NNS'),\n",
      " ('worse', 'JJR'),\n",
      " ('experience', 'NN'),\n",
      " ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "token_tag = preprocess(text)\n",
    "pprint(token_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noun Phrase \n",
    "np_pattern = 'NP:{<DT>?<JJ.*>*<NN.*>+}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  For/IN\n",
      "  nearly/RB\n",
      "  (NP a/DT decade/NN)\n",
      "  ,/,\n",
      "  they/PRP\n",
      "  argue/VBP\n",
      "  ,/,\n",
      "  (NP Facebook/NNP)\n",
      "  has/VBZ\n",
      "  made/VBN\n",
      "  (NP “/NNP)\n",
      "  (NP serial/JJ defensive/JJ acquisitions/NNS)\n",
      "  ”/VBP\n",
      "  to/TO\n",
      "  protect/VB\n",
      "  its/PRP$\n",
      "  (NP dominant/JJ position/NN)\n",
      "  in/IN\n",
      "  (NP the/DT market/NN)\n",
      "  for/IN\n",
      "  (NP social/JJ networks/NNS)\n",
      "  ,/,\n",
      "  according/VBG\n",
      "  to/TO\n",
      "  (NP slides/NNS)\n",
      "  they/PRP\n",
      "  have/VBP\n",
      "  shown/VBN\n",
      "  (NP government/NN officials/NNS)\n",
      "  ./.\n",
      "  Scooping/VBG\n",
      "  up/RP\n",
      "  (NP nascent/JJ rivals/NNS)\n",
      "  ,/,\n",
      "  they/PRP\n",
      "  assert/VBP\n",
      "  ,/,\n",
      "  can/MD\n",
      "  allow/VB\n",
      "  (NP Facebook/NNP)\n",
      "  to/TO\n",
      "  charge/VB\n",
      "  (NP advertisers/NNS)\n",
      "  (NP higher/JJR prices/NNS)\n",
      "  and/CC\n",
      "  can/MD\n",
      "  give/VB\n",
      "  (NP users/NNS)\n",
      "  (NP worse/JJR experience/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "noun_ner = nltk.RegexpParser(np_pattern)\n",
    "ner_extraction = noun_ner.parse(token_tag)\n",
    "print(ner_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import conlltags2tree, tree2conlltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('For', 'IN', 'O'),\n",
      " ('nearly', 'RB', 'O'),\n",
      " ('a', 'DT', 'B-NP'),\n",
      " ('decade', 'NN', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('they', 'PRP', 'O'),\n",
      " ('argue', 'VBP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('Facebook', 'NNP', 'B-NP'),\n",
      " ('has', 'VBZ', 'O'),\n",
      " ('made', 'VBN', 'O'),\n",
      " ('“', 'NNP', 'B-NP'),\n",
      " ('serial', 'JJ', 'B-NP'),\n",
      " ('defensive', 'JJ', 'I-NP'),\n",
      " ('acquisitions', 'NNS', 'I-NP'),\n",
      " ('”', 'VBP', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('protect', 'VB', 'O'),\n",
      " ('its', 'PRP$', 'O'),\n",
      " ('dominant', 'JJ', 'B-NP'),\n",
      " ('position', 'NN', 'I-NP'),\n",
      " ('in', 'IN', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('market', 'NN', 'I-NP'),\n",
      " ('for', 'IN', 'O'),\n",
      " ('social', 'JJ', 'B-NP'),\n",
      " ('networks', 'NNS', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('according', 'VBG', 'O'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('slides', 'NNS', 'B-NP'),\n",
      " ('they', 'PRP', 'O'),\n",
      " ('have', 'VBP', 'O'),\n",
      " ('shown', 'VBN', 'O'),\n",
      " ('government', 'NN', 'B-NP'),\n",
      " ('officials', 'NNS', 'I-NP'),\n",
      " ('.', '.', 'O'),\n",
      " ('Scooping', 'VBG', 'O'),\n",
      " ('up', 'RP', 'O'),\n",
      " ('nascent', 'JJ', 'B-NP'),\n",
      " ('rivals', 'NNS', 'I-NP'),\n",
      " (',', ',', 'O'),\n",
      " ('they', 'PRP', 'O'),\n",
      " ('assert', 'VBP', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('can', 'MD', 'O'),\n",
      " ('allow', 'VB', 'O'),\n",
      " ('Facebook', 'NNP', 'B-NP'),\n",
      " ('to', 'TO', 'O'),\n",
      " ('charge', 'VB', 'O'),\n",
      " ('advertisers', 'NNS', 'B-NP'),\n",
      " ('higher', 'JJR', 'B-NP'),\n",
      " ('prices', 'NNS', 'I-NP'),\n",
      " ('and', 'CC', 'O'),\n",
      " ('can', 'MD', 'O'),\n",
      " ('give', 'VB', 'O'),\n",
      " ('users', 'NNS', 'B-NP'),\n",
      " ('worse', 'JJR', 'B-NP'),\n",
      " ('experience', 'NN', 'I-NP'),\n",
      " ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "ner_tags = tree2conlltags(ner_extraction)\n",
    "pprint(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/venkateshmurugadas/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/venkateshmurugadas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  decade/NN\n",
      "  (PERSON Facebook/NNP)\n",
      "  “/NNP\n",
      "  acquisitions/NNS\n",
      "  position/NN\n",
      "  market/NN\n",
      "  networks/NNS\n",
      "  slides/NNS\n",
      "  government/NN\n",
      "  officials/NNS\n",
      "  rivals/NNS\n",
      "  (PERSON Facebook/NNP)\n",
      "  advertisers/NNS\n",
      "  prices/NNS\n",
      "  users/NNS\n",
      "  experience/NN\n"
     ]
    }
   ],
   "source": [
    "#So to do all the above in one function , there is a function named ne_chunk \n",
    "\n",
    "ner_chunk = nltk.ne_chunk(pos_tag(word_tokenize(text)))\n",
    "for noun in str(ner_chunk).split('\\n'):\n",
    "    if '/NN' in noun:\n",
    "        print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
